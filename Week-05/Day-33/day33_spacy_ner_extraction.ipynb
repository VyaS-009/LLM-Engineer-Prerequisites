{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 33 – Named Entity Recognition using spaCy\n",
    "### Extract Entities from Complaints / Tickets / Documents\n",
    "\n",
    "Today you'll use spaCy's NER system to automate entity extraction from text.\n",
    "\n",
    "#### Goals:\n",
    "- Load spaCy NER model\n",
    "- Extract entities such as PERSON, ORG, GPE, DATE, MONEY, etc.\n",
    "- Visualize entities using spaCy displacy\n",
    "- Build a reusable entity extraction function\n",
    "- Generate a structured, machine-readable entity dictionary\n",
    "\n",
    "This is key for document automation and AI-driven grievance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"spaCy model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Document / Complaint Dataset\n",
    "We simulate real-world grievance/ticket texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"I, John Doe, want to report that my laptop was stolen near MG Road on 5th January 2024.\",\n",
    "    \"Payment of $250 was deducted twice from my HDFC account. Please help resolve this immediately.\",\n",
    "    \"The service center at Hyderabad refused to repair my phone even though it is under warranty.\",\n",
    "    \"My name is Ramesh Kumar. I filed a complaint last week but haven't received any update.\",\n",
    "    \"Uber charged me ₹560 for a ride I never booked on 14th Feb 2023.\",\n",
    "    \"I work at Infosys and need a salary slip for my account verification process.\",\n",
    "    \"There is a fraud transaction of Rs 12,000 on my SBI credit card yesterday.\",\n",
    "    \"My passport application ID AX92011 has been pending for 3 weeks.\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"document\": documents})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run NER on Each Document\n",
    "Let's inspect extracted entities for one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = nlp(documents[0])\n",
    "for ent in sample_doc.ents:\n",
    "    print(ent.text, \"--\", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Entities with spaCy Displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(sample_doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reusable Entity Extraction Function\n",
    "Returns a dictionary grouped by entity label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entity_dict = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in entity_dict:\n",
    "            entity_dict[ent.label_] = []\n",
    "        entity_dict[ent.label_].append(ent.text)\n",
    "    return entity_dict\n",
    "\n",
    "# Test on sample\n",
    "extract_entities(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply to All Documents and Create Structured Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entities'] = df['document'].apply(extract_entities)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export as JSON (Useful for Automation Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = df.to_json(orient='records', indent=2)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "- Loaded spaCy NER model\n",
    "- Extracted PERSON, ORG, GPE, MONEY, DATE, CARDINAL, etc.\n",
    "- Visualized NER outputs\n",
    "- Created reusable entity extraction function\n",
    "- Built structured JSON output for automation systems\n",
    "\n",
    "**Deliverable:** `day33_spacy_ner_extraction.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
