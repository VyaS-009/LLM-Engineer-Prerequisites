{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 08 – Python Scripting: Automate Data Fetching & Cleaning\n",
    "### Objective: Build a reusable Python workflow that pulls, cleans, and saves real-world data.\n",
    "\n",
    "In this notebook you’ll learn how to:\n",
    "- Fetch data (CSV + JSON)\n",
    "- Clean and preprocess it automatically\n",
    "- Combine datasets\n",
    "- Save cleaned data to disk\n",
    "- Log every step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create folders for raw and cleaned data\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('data/cleaned', exist_ok=True)\n",
    "\n",
    "def log(message):\n",
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Fetch Data from Public APIs and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b760117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 10:18:00] Fetching COVID-19 JSON data...\n",
      "[2025-10-28 10:18:02] COVID data fetched successfully → 231 rows\n",
      "[2025-10-28 10:18:02] Fetching Movies CSV data...\n",
      "[2025-10-28 10:18:03] Movies data fetched successfully → 146 rows\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Fetch JSON data (COVID-19 summary)\n",
    "json_url = \"https://disease.sh/v3/covid-19/countries\"\n",
    "log(\"Fetching COVID-19 JSON data...\")\n",
    "response = requests.get(json_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    covid_data = response.json()\n",
    "    countries_df = pd.json_normalize(covid_data)\n",
    "    countries_df.to_csv('data/raw/covid_summary.csv', index=False)\n",
    "    log(f\"COVID data fetched successfully → {countries_df.shape[0]} rows\")\n",
    "else:\n",
    "    log(f\"Failed to fetch JSON data: {response.status_code}\")\n",
    "\n",
    "# Example 2: Fetch CSV from GitHub (sample movies dataset)\n",
    "csv_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/fandango/fandango_score_comparison.csv\"\n",
    "log(\"Fetching Movies CSV data...\")\n",
    "movies_df = pd.read_csv(csv_url)\n",
    "movies_df.to_csv('data/raw/movies.csv', index=False)\n",
    "log(f\"Movies data fetched successfully → {movies_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a71cf2",
   "metadata": {},
   "source": [
    "## 3️⃣ Inspect and Clean the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fccb8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 10:31:35] Inspecting datasets...\n",
      "         updated      country   cases  todayCases  deaths  todayDeaths  \\\n",
      "0  1761626698435  Afghanistan  234174           0    7996            0   \n",
      "1  1761626698428      Albania  334863           0    3605            0   \n",
      "2  1761626698431      Algeria  272010           0    6881            0   \n",
      "\n",
      "   recovered  todayRecovered  active  critical  ...  oneTestPerPeople  \\\n",
      "0     211080               0   15098         0  ...                29   \n",
      "1     330233               0    1025         0  ...                 1   \n",
      "2     183061               0   82068         0  ...               196   \n",
      "\n",
      "   activePerOneMillion  recoveredPerOneMillion  criticalPerOneMillion  \\\n",
      "0               370.46                 5179.32                    0.0   \n",
      "1               357.59               115209.32                    0.0   \n",
      "2              1809.65                 4036.61                    0.0   \n",
      "\n",
      "   countryInfo._id countryInfo.iso2  countryInfo.iso3  countryInfo.lat  \\\n",
      "0              4.0               AF               AFG             33.0   \n",
      "1              8.0               AL               ALB             41.0   \n",
      "2             12.0               DZ               DZA             28.0   \n",
      "\n",
      "   countryInfo.long                            countryInfo.flag  \n",
      "0              65.0  https://disease.sh/assets/img/flags/af.png  \n",
      "1              20.0  https://disease.sh/assets/img/flags/al.png  \n",
      "2               3.0  https://disease.sh/assets/img/flags/dz.png  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "                             FILM  RottenTomatoes  RottenTomatoes_User  \\\n",
      "0  Avengers: Age of Ultron (2015)              74                   86   \n",
      "1               Cinderella (2015)              85                   80   \n",
      "2                  Ant-Man (2015)              80                   90   \n",
      "\n",
      "   Metacritic  Metacritic_User  IMDB  Fandango_Stars  Fandango_Ratingvalue  \\\n",
      "0          66              7.1   7.8             5.0                   4.5   \n",
      "1          67              7.5   7.1             5.0                   4.5   \n",
      "2          64              8.1   7.8             5.0                   4.5   \n",
      "\n",
      "   RT_norm  RT_user_norm  ...  IMDB_norm  RT_norm_round  RT_user_norm_round  \\\n",
      "0     3.70           4.3  ...       3.90            3.5                 4.5   \n",
      "1     4.25           4.0  ...       3.55            4.5                 4.0   \n",
      "2     4.00           4.5  ...       3.90            4.0                 4.5   \n",
      "\n",
      "   Metacritic_norm_round  Metacritic_user_norm_round  IMDB_norm_round  \\\n",
      "0                    3.5                         3.5              4.0   \n",
      "1                    3.5                         4.0              3.5   \n",
      "2                    3.0                         4.0              4.0   \n",
      "\n",
      "   Metacritic_user_vote_count  IMDB_user_vote_count  Fandango_votes  \\\n",
      "0                        1330                271107           14846   \n",
      "1                         249                 65709           12640   \n",
      "2                         627                103660           12055   \n",
      "\n",
      "   Fandango_Difference  \n",
      "0                  0.5  \n",
      "1                  0.5  \n",
      "2                  0.5  \n",
      "\n",
      "[3 rows x 22 columns]\n",
      "[2025-10-28 10:31:35] Cleaning COVID dataset...\n",
      "[2025-10-28 10:31:35] Cleaning Movies dataset...\n",
      "[2025-10-28 10:31:35] Movies data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Basic inspection\n",
    "log(\"Inspecting datasets...\")\n",
    "print(countries_df.head(3))\n",
    "print(movies_df.head(3))\n",
    "\n",
    "# Cleaning COVID data\n",
    "log(\"Cleaning COVID dataset...\")\n",
    "covid_clean = countries_df[['country', 'cases', 'deaths', 'recovered']].copy()\n",
    "covid_clean.columns = ['country', 'covid_positive_confirmed', 'deaths', 'recovered'] # Rename 'cases' to 'confirmed' for consistency\n",
    "covid_clean.dropna(inplace=True)\n",
    "\n",
    "# Cleaning Movies data\n",
    "log(\"Cleaning Movies dataset...\")\n",
    "movies_clean = movies_df[['FILM', 'RottenTomatoes', 'IMDB', 'Metacritic']].copy()\n",
    "movies_clean.dropna(inplace=True)\n",
    "movies_clean.rename(columns={'FILM': 'film', 'RottenTomatoes': 'rotten_tomatoes', 'IMDB': 'imdb_rating', 'Metacritic': 'metacritic_rating'}, inplace=True)\n",
    "log(\"Movies data cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Combine and Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 10:31:39] Saving cleaned datasets...\n",
      "[2025-10-28 10:31:39] Cleaned data saved successfully ✅\n"
     ]
    }
   ],
   "source": [
    "log(\"Saving cleaned datasets...\")\n",
    "covid_clean.to_csv('data/cleaned/covid_clean.csv', index=False)\n",
    "movies_clean.to_csv('data/cleaned/movies_clean.csv', index=False)\n",
    "\n",
    "log(\"Cleaned data saved successfully ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Automate with Functions (Reusable Script Design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-28 10:18:52] Fetching CSV from https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\n",
      "[2025-10-28 10:18:53] Saved → data/raw/tips.csv (244 rows)\n",
      "[2025-10-28 10:18:53] Automation complete ✅\n"
     ]
    }
   ],
   "source": [
    "def fetch_csv(url, save_path):\n",
    "    log(f\"Fetching CSV from {url}\")\n",
    "    df = pd.read_csv(url)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    log(f\"Saved → {save_path} ({df.shape[0]} rows)\")\n",
    "    return df\n",
    "\n",
    "def clean_dataframe(df, dropna=True, rename_dict=None):\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    if rename_dict:\n",
    "        df = df.rename(columns=rename_dict)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\n",
    "    df = fetch_csv(url, 'data/raw/tips.csv')\n",
    "    clean_df = clean_dataframe(df, rename_dict={'total_bill':'bill', 'tip':'gratuity'})\n",
    "    clean_df.to_csv('data/cleaned/tips_clean.csv', index=False)\n",
    "    log(\"Automation complete ✅\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "- You learned to automate repetitive data collection.\n",
    "- Cleaned both JSON and CSV data.\n",
    "- Created a reusable automation pattern (`main()`, logging, modular helpers).\n",
    "- This structure is how ML engineers handle real data pipelines before model training.\n",
    "\n",
    "**Next → Day 09: Exploratory Data Analysis (EDA) Automation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
